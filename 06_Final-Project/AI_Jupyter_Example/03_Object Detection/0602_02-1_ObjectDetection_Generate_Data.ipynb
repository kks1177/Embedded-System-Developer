{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f961ae83",
   "metadata": {},
   "source": [
    "# 1. train data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58681626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bready.object_detection_tools import ObjectDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b542bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성\n",
    "trainer = ObjectDetector.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edcfe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_data_path = \"C:/Users/user/01_AI_ObjectDetection/dataset/Images\"\n",
    "# annotation_data_path = \"C:/Users/user/01_AI_ObjectDetection/dataset/annotations\"\n",
    "# class_file_path = \"C:/Users/user/01_AI_ObjectDetection/classes.txt\"\n",
    "\n",
    "original_data_path = \"dataset2/Images\"\n",
    "annotation_data_path = \"dataset2/annotations\"\n",
    "class_file_path = \"classes.txt\"\n",
    "final_data_path = \"dataset2_tfrecord\"\n",
    "\n",
    "trainer.setImageDirectory(original_data_path)\n",
    "trainer.setAnnotationDirectory(annotation_data_path)\n",
    "trainer.setClassPath(class_file_path)\n",
    "trainer.setDataDirectory(final_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1ff6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted xml to csv : dataset2_tfrecord\\train.csv\n",
      "Successfully created the TFRecords: dataset2_tfrecord\\train.record\n",
      "Successfully created the label pbtxt: dataset2_tfrecord\\train_label.pbtxt\n",
      "The class file has been copied to the \"dataset2_tfrecord\" folder with the name detection_classes.txt.\n"
     ]
    }
   ],
   "source": [
    "trainer.generateTFRecords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552f2eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_path = \"dataset2_tfrecord\"\n",
    "save_model_path = \"training_models2_checkpoint\"\n",
    "\n",
    "trainer.setDataDirectory(train_data_path)\n",
    "trainer.setSaveModelDirectory(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dca80f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "steps = 200\n",
    "trainer.setMaxSteps(steps)\n",
    "trainer.setBatchSize(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0da1547",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.setAugmentation_Option(ObjectDetector.Image_Augmentation.HORIZONTAL_FLIP, False)\n",
    "trainer.setAugmentation_Option(ObjectDetector.Image_Augmentation.VERTICAL_FLIP, False)\n",
    "trainer.setAugmentation_Option(ObjectDetector.Image_Augmentation.RANDOM_BRIGHTNESS, True)\n",
    "trainer.setAugmentation_Option(ObjectDetector.Image_Augmentation.SSD_RANDOM_CROP, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ffe6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\bready\\object_detection_tools\\lib\\training_tools\\trainer.py:242: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "\n",
      "총 이미지 개수 : 200\n",
      "학습 횟수 : 200번으로 설정됨\n",
      "\n",
      "INFO:tensorflow:Writing pipeline config file to dataset2_tfrecord\\pipeline.config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.5.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Saving pipeline config file to directory training_models2_checkpoint\n",
      "INFO:tensorflow:Writing pipeline config file to training_models2_checkpoint\\pipeline.config\n",
      "WARNING:tensorflow:From C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\object_detection\\model_lib_v2.py:559: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['dataset2_tfrecord\\\\train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['dataset2_tfrecord\\\\train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Step 1: Loss/localization_loss=3.3944, Loss/classification_loss=0.7245 Loss/regularization_loss=0.0854, Loss/total_loss=4.2043, learning_rate=0.0040 (58.634 sec/step)\n",
      "Step 2: Loss/localization_loss=3.3779, Loss/classification_loss=0.7550 Loss/regularization_loss=0.0854, Loss/total_loss=4.2183, learning_rate=0.0040 (9.795 sec/step)\n",
      "Step 3: Loss/localization_loss=3.3263, Loss/classification_loss=0.6511 Loss/regularization_loss=0.0854, Loss/total_loss=4.0628, learning_rate=0.0040 (10.685 sec/step)\n",
      "Step 4: Loss/localization_loss=3.3727, Loss/classification_loss=0.7582 Loss/regularization_loss=0.0854, Loss/total_loss=4.2163, learning_rate=0.0041 (9.761 sec/step)\n",
      "Step 5: Loss/localization_loss=3.2635, Loss/classification_loss=0.7904 Loss/regularization_loss=0.0854, Loss/total_loss=4.1394, learning_rate=0.0041 (10.130 sec/step)\n",
      "Step 6: Loss/localization_loss=3.2849, Loss/classification_loss=0.6728 Loss/regularization_loss=0.0854, Loss/total_loss=4.0431, learning_rate=0.0041 (9.944 sec/step)\n",
      "Step 7: Loss/localization_loss=3.1748, Loss/classification_loss=0.7157 Loss/regularization_loss=0.0854, Loss/total_loss=3.9759, learning_rate=0.0041 (9.642 sec/step)\n",
      "Step 8: Loss/localization_loss=3.1278, Loss/classification_loss=0.6994 Loss/regularization_loss=0.0854, Loss/total_loss=3.9126, learning_rate=0.0041 (9.246 sec/step)\n",
      "Step 9: Loss/localization_loss=2.9913, Loss/classification_loss=0.6995 Loss/regularization_loss=0.0854, Loss/total_loss=3.7763, learning_rate=0.0041 (8.928 sec/step)\n",
      "Step 10: Loss/localization_loss=2.9874, Loss/classification_loss=0.6731 Loss/regularization_loss=0.0854, Loss/total_loss=3.7460, learning_rate=0.0041 (8.939 sec/step)\n",
      "Step 11: Loss/localization_loss=2.9895, Loss/classification_loss=0.6819 Loss/regularization_loss=0.0854, Loss/total_loss=3.7568, learning_rate=0.0042 (9.083 sec/step)\n",
      "Step 12: Loss/localization_loss=2.9278, Loss/classification_loss=0.6525 Loss/regularization_loss=0.0854, Loss/total_loss=3.6658, learning_rate=0.0042 (9.139 sec/step)\n",
      "Step 13: Loss/localization_loss=2.8939, Loss/classification_loss=0.6255 Loss/regularization_loss=0.0854, Loss/total_loss=3.6048, learning_rate=0.0042 (9.137 sec/step)\n",
      "Step 14: Loss/localization_loss=2.6394, Loss/classification_loss=0.6586 Loss/regularization_loss=0.0854, Loss/total_loss=3.3835, learning_rate=0.0042 (9.114 sec/step)\n",
      "Step 15: Loss/localization_loss=2.4965, Loss/classification_loss=0.6377 Loss/regularization_loss=0.0854, Loss/total_loss=3.2197, learning_rate=0.0042 (8.993 sec/step)\n",
      "Step 16: Loss/localization_loss=2.4884, Loss/classification_loss=0.5854 Loss/regularization_loss=0.0854, Loss/total_loss=3.1593, learning_rate=0.0042 (9.174 sec/step)\n",
      "Step 17: Loss/localization_loss=2.1056, Loss/classification_loss=0.5788 Loss/regularization_loss=0.0854, Loss/total_loss=2.7699, learning_rate=0.0042 (9.184 sec/step)\n",
      "Step 18: Loss/localization_loss=2.7971, Loss/classification_loss=0.7082 Loss/regularization_loss=0.0854, Loss/total_loss=3.5908, learning_rate=0.0043 (9.442 sec/step)\n",
      "Step 19: Loss/localization_loss=1.9700, Loss/classification_loss=0.5866 Loss/regularization_loss=0.0854, Loss/total_loss=2.6420, learning_rate=0.0043 (9.354 sec/step)\n",
      "Step 20: Loss/localization_loss=1.9587, Loss/classification_loss=0.5744 Loss/regularization_loss=0.0854, Loss/total_loss=2.6185, learning_rate=0.0043 (11.212 sec/step)\n",
      "Step 21: Loss/localization_loss=1.7953, Loss/classification_loss=0.5689 Loss/regularization_loss=0.0854, Loss/total_loss=2.4496, learning_rate=0.0043 (10.009 sec/step)\n",
      "Step 22: Loss/localization_loss=1.5778, Loss/classification_loss=0.5609 Loss/regularization_loss=0.0855, Loss/total_loss=2.2241, learning_rate=0.0043 (9.283 sec/step)\n",
      "Step 23: Loss/localization_loss=1.4106, Loss/classification_loss=0.6131 Loss/regularization_loss=0.0855, Loss/total_loss=2.1092, learning_rate=0.0043 (9.164 sec/step)\n",
      "Step 24: Loss/localization_loss=1.1775, Loss/classification_loss=0.6261 Loss/regularization_loss=0.0855, Loss/total_loss=1.8891, learning_rate=0.0043 (9.842 sec/step)\n",
      "Step 25: Loss/localization_loss=1.3464, Loss/classification_loss=0.4948 Loss/regularization_loss=0.0855, Loss/total_loss=1.9266, learning_rate=0.0044 (10.104 sec/step)\n",
      "Step 26: Loss/localization_loss=1.5010, Loss/classification_loss=0.5959 Loss/regularization_loss=0.0855, Loss/total_loss=2.1823, learning_rate=0.0044 (9.562 sec/step)\n",
      "Step 27: Loss/localization_loss=0.9734, Loss/classification_loss=0.5755 Loss/regularization_loss=0.0855, Loss/total_loss=1.6343, learning_rate=0.0044 (11.133 sec/step)\n",
      "Step 28: Loss/localization_loss=1.0130, Loss/classification_loss=0.4609 Loss/regularization_loss=0.0855, Loss/total_loss=1.5594, learning_rate=0.0044 (10.468 sec/step)\n",
      "Step 29: Loss/localization_loss=0.8696, Loss/classification_loss=0.4267 Loss/regularization_loss=0.0855, Loss/total_loss=1.3818, learning_rate=0.0044 (10.319 sec/step)\n",
      "Step 30: Loss/localization_loss=1.0525, Loss/classification_loss=0.4646 Loss/regularization_loss=0.0855, Loss/total_loss=1.6025, learning_rate=0.0044 (9.328 sec/step)\n",
      "Step 31: Loss/localization_loss=1.3049, Loss/classification_loss=0.5039 Loss/regularization_loss=0.0855, Loss/total_loss=1.8942, learning_rate=0.0044 (10.487 sec/step)\n",
      "Step 32: Loss/localization_loss=0.7109, Loss/classification_loss=0.4651 Loss/regularization_loss=0.0855, Loss/total_loss=1.2615, learning_rate=0.0044 (10.959 sec/step)\n",
      "Step 33: Loss/localization_loss=0.9231, Loss/classification_loss=0.5013 Loss/regularization_loss=0.0855, Loss/total_loss=1.5099, learning_rate=0.0045 (9.996 sec/step)\n",
      "Step 34: Loss/localization_loss=0.7227, Loss/classification_loss=0.4329 Loss/regularization_loss=0.0855, Loss/total_loss=1.2411, learning_rate=0.0045 (10.497 sec/step)\n",
      "Step 35: Loss/localization_loss=0.7663, Loss/classification_loss=0.4203 Loss/regularization_loss=0.0855, Loss/total_loss=1.2721, learning_rate=0.0045 (9.575 sec/step)\n",
      "Step 36: Loss/localization_loss=1.0339, Loss/classification_loss=0.4535 Loss/regularization_loss=0.0855, Loss/total_loss=1.5729, learning_rate=0.0045 (9.437 sec/step)\n",
      "Step 37: Loss/localization_loss=0.6334, Loss/classification_loss=0.3771 Loss/regularization_loss=0.0855, Loss/total_loss=1.0960, learning_rate=0.0045 (10.485 sec/step)\n",
      "Step 38: Loss/localization_loss=1.1244, Loss/classification_loss=0.4291 Loss/regularization_loss=0.0855, Loss/total_loss=1.6391, learning_rate=0.0045 (10.907 sec/step)\n",
      "Step 39: Loss/localization_loss=0.8205, Loss/classification_loss=0.4515 Loss/regularization_loss=0.0855, Loss/total_loss=1.3575, learning_rate=0.0045 (10.009 sec/step)\n",
      "Step 40: Loss/localization_loss=0.5634, Loss/classification_loss=0.3551 Loss/regularization_loss=0.0855, Loss/total_loss=1.0040, learning_rate=0.0046 (9.831 sec/step)\n",
      "Step 41: Loss/localization_loss=0.7530, Loss/classification_loss=0.3617 Loss/regularization_loss=0.0855, Loss/total_loss=1.2002, learning_rate=0.0046 (9.321 sec/step)\n",
      "Step 42: Loss/localization_loss=0.8641, Loss/classification_loss=0.4719 Loss/regularization_loss=0.0855, Loss/total_loss=1.4214, learning_rate=0.0046 (9.065 sec/step)\n",
      "Step 43: Loss/localization_loss=0.8540, Loss/classification_loss=0.4227 Loss/regularization_loss=0.0855, Loss/total_loss=1.3623, learning_rate=0.0046 (9.444 sec/step)\n",
      "Step 44: Loss/localization_loss=0.8198, Loss/classification_loss=0.3825 Loss/regularization_loss=0.0855, Loss/total_loss=1.2878, learning_rate=0.0046 (9.411 sec/step)\n",
      "Step 45: Loss/localization_loss=0.5806, Loss/classification_loss=0.3490 Loss/regularization_loss=0.0855, Loss/total_loss=1.0150, learning_rate=0.0046 (9.250 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 46: Loss/localization_loss=0.9456, Loss/classification_loss=0.4440 Loss/regularization_loss=0.0855, Loss/total_loss=1.4750, learning_rate=0.0046 (9.394 sec/step)\n",
      "Step 47: Loss/localization_loss=0.6823, Loss/classification_loss=0.3852 Loss/regularization_loss=0.0855, Loss/total_loss=1.1530, learning_rate=0.0047 (9.015 sec/step)\n",
      "Step 48: Loss/localization_loss=0.5457, Loss/classification_loss=0.3370 Loss/regularization_loss=0.0855, Loss/total_loss=0.9681, learning_rate=0.0047 (9.154 sec/step)\n",
      "Step 49: Loss/localization_loss=0.6114, Loss/classification_loss=0.3963 Loss/regularization_loss=0.0855, Loss/total_loss=1.0933, learning_rate=0.0047 (9.202 sec/step)\n",
      "Step 50: Loss/localization_loss=0.7573, Loss/classification_loss=0.3907 Loss/regularization_loss=0.0855, Loss/total_loss=1.2335, learning_rate=0.0047 (9.238 sec/step)\n",
      "Step 51: Loss/localization_loss=0.7075, Loss/classification_loss=0.2911 Loss/regularization_loss=0.0855, Loss/total_loss=1.0841, learning_rate=0.0047 (9.046 sec/step)\n",
      "Step 52: Loss/localization_loss=1.0235, Loss/classification_loss=0.3329 Loss/regularization_loss=0.0855, Loss/total_loss=1.4419, learning_rate=0.0047 (9.214 sec/step)\n",
      "Step 53: Loss/localization_loss=0.7165, Loss/classification_loss=0.3218 Loss/regularization_loss=0.0855, Loss/total_loss=1.1237, learning_rate=0.0047 (9.863 sec/step)\n",
      "Step 54: Loss/localization_loss=0.5707, Loss/classification_loss=0.3596 Loss/regularization_loss=0.0855, Loss/total_loss=1.0158, learning_rate=0.0048 (9.042 sec/step)\n",
      "Step 55: Loss/localization_loss=0.7882, Loss/classification_loss=0.3706 Loss/regularization_loss=0.0855, Loss/total_loss=1.2443, learning_rate=0.0048 (8.929 sec/step)\n",
      "Step 56: Loss/localization_loss=0.4550, Loss/classification_loss=0.2704 Loss/regularization_loss=0.0855, Loss/total_loss=0.8109, learning_rate=0.0048 (8.901 sec/step)\n",
      "Step 57: Loss/localization_loss=0.3776, Loss/classification_loss=0.2828 Loss/regularization_loss=0.0855, Loss/total_loss=0.7459, learning_rate=0.0048 (8.990 sec/step)\n",
      "Step 58: Loss/localization_loss=0.7565, Loss/classification_loss=0.3194 Loss/regularization_loss=0.0855, Loss/total_loss=1.1614, learning_rate=0.0048 (8.920 sec/step)\n",
      "Step 59: Loss/localization_loss=0.3595, Loss/classification_loss=0.2720 Loss/regularization_loss=0.0855, Loss/total_loss=0.7170, learning_rate=0.0048 (8.917 sec/step)\n",
      "Step 60: Loss/localization_loss=0.4781, Loss/classification_loss=0.2972 Loss/regularization_loss=0.0855, Loss/total_loss=0.8608, learning_rate=0.0048 (9.150 sec/step)\n",
      "Step 61: Loss/localization_loss=0.5316, Loss/classification_loss=0.2735 Loss/regularization_loss=0.0855, Loss/total_loss=0.8906, learning_rate=0.0049 (9.945 sec/step)\n",
      "Step 62: Loss/localization_loss=0.4456, Loss/classification_loss=0.2567 Loss/regularization_loss=0.0855, Loss/total_loss=0.7879, learning_rate=0.0049 (8.813 sec/step)\n",
      "Step 63: Loss/localization_loss=0.5101, Loss/classification_loss=0.2805 Loss/regularization_loss=0.0855, Loss/total_loss=0.8762, learning_rate=0.0049 (6.469 sec/step)\n",
      "Step 64: Loss/localization_loss=0.5338, Loss/classification_loss=0.3783 Loss/regularization_loss=0.0855, Loss/total_loss=0.9975, learning_rate=0.0049 (6.157 sec/step)\n",
      "Step 65: Loss/localization_loss=0.6868, Loss/classification_loss=0.3013 Loss/regularization_loss=0.0855, Loss/total_loss=1.0736, learning_rate=0.0049 (5.840 sec/step)\n",
      "Step 66: Loss/localization_loss=0.6049, Loss/classification_loss=0.2578 Loss/regularization_loss=0.0855, Loss/total_loss=0.9481, learning_rate=0.0049 (5.894 sec/step)\n",
      "Step 67: Loss/localization_loss=0.4773, Loss/classification_loss=0.2871 Loss/regularization_loss=0.0855, Loss/total_loss=0.8499, learning_rate=0.0049 (5.950 sec/step)\n",
      "Step 68: Loss/localization_loss=0.3438, Loss/classification_loss=0.2506 Loss/regularization_loss=0.0855, Loss/total_loss=0.6799, learning_rate=0.0050 (5.881 sec/step)\n",
      "Step 69: Loss/localization_loss=0.5498, Loss/classification_loss=0.2371 Loss/regularization_loss=0.0855, Loss/total_loss=0.8725, learning_rate=0.0050 (5.908 sec/step)\n",
      "Step 70: Loss/localization_loss=0.4092, Loss/classification_loss=0.2353 Loss/regularization_loss=0.0855, Loss/total_loss=0.7300, learning_rate=0.0050 (5.836 sec/step)\n",
      "Step 71: Loss/localization_loss=0.4188, Loss/classification_loss=0.2559 Loss/regularization_loss=0.0855, Loss/total_loss=0.7603, learning_rate=0.0050 (5.996 sec/step)\n",
      "Step 72: Loss/localization_loss=0.4386, Loss/classification_loss=0.2849 Loss/regularization_loss=0.0855, Loss/total_loss=0.8091, learning_rate=0.0050 (5.937 sec/step)\n",
      "Step 73: Loss/localization_loss=0.4490, Loss/classification_loss=0.2712 Loss/regularization_loss=0.0855, Loss/total_loss=0.8058, learning_rate=0.0050 (5.939 sec/step)\n",
      "Step 74: Loss/localization_loss=0.4260, Loss/classification_loss=0.2558 Loss/regularization_loss=0.0855, Loss/total_loss=0.7673, learning_rate=0.0050 (5.924 sec/step)\n",
      "Step 75: Loss/localization_loss=0.3363, Loss/classification_loss=0.2128 Loss/regularization_loss=0.0855, Loss/total_loss=0.6346, learning_rate=0.0051 (5.876 sec/step)\n",
      "Step 76: Loss/localization_loss=0.3450, Loss/classification_loss=0.2484 Loss/regularization_loss=0.0855, Loss/total_loss=0.6790, learning_rate=0.0051 (5.824 sec/step)\n",
      "Step 77: Loss/localization_loss=0.4981, Loss/classification_loss=0.3248 Loss/regularization_loss=0.0855, Loss/total_loss=0.9084, learning_rate=0.0051 (5.929 sec/step)\n",
      "Step 78: Loss/localization_loss=0.5303, Loss/classification_loss=0.2184 Loss/regularization_loss=0.0855, Loss/total_loss=0.8342, learning_rate=0.0051 (5.890 sec/step)\n",
      "Step 79: Loss/localization_loss=0.5251, Loss/classification_loss=0.3371 Loss/regularization_loss=0.0855, Loss/total_loss=0.9476, learning_rate=0.0051 (5.950 sec/step)\n",
      "Step 80: Loss/localization_loss=0.6205, Loss/classification_loss=0.2747 Loss/regularization_loss=0.0855, Loss/total_loss=0.9807, learning_rate=0.0051 (5.874 sec/step)\n",
      "Step 81: Loss/localization_loss=0.6217, Loss/classification_loss=0.2673 Loss/regularization_loss=0.0855, Loss/total_loss=0.9745, learning_rate=0.0051 (5.932 sec/step)\n",
      "Step 82: Loss/localization_loss=0.4837, Loss/classification_loss=0.2248 Loss/regularization_loss=0.0855, Loss/total_loss=0.7940, learning_rate=0.0051 (5.962 sec/step)\n",
      "Step 83: Loss/localization_loss=0.7562, Loss/classification_loss=0.3574 Loss/regularization_loss=0.0855, Loss/total_loss=1.1991, learning_rate=0.0052 (6.024 sec/step)\n",
      "Step 84: Loss/localization_loss=0.4986, Loss/classification_loss=0.3009 Loss/regularization_loss=0.0855, Loss/total_loss=0.8850, learning_rate=0.0052 (5.956 sec/step)\n",
      "Step 85: Loss/localization_loss=0.3357, Loss/classification_loss=0.2082 Loss/regularization_loss=0.0855, Loss/total_loss=0.6294, learning_rate=0.0052 (5.975 sec/step)\n",
      "Step 86: Loss/localization_loss=0.4513, Loss/classification_loss=0.2181 Loss/regularization_loss=0.0855, Loss/total_loss=0.7549, learning_rate=0.0052 (5.926 sec/step)\n",
      "Step 87: Loss/localization_loss=0.3773, Loss/classification_loss=0.2217 Loss/regularization_loss=0.0855, Loss/total_loss=0.6845, learning_rate=0.0052 (6.077 sec/step)\n",
      "Step 88: Loss/localization_loss=0.5486, Loss/classification_loss=0.2423 Loss/regularization_loss=0.0855, Loss/total_loss=0.8764, learning_rate=0.0052 (6.135 sec/step)\n",
      "Step 89: Loss/localization_loss=0.4433, Loss/classification_loss=0.1816 Loss/regularization_loss=0.0855, Loss/total_loss=0.7103, learning_rate=0.0052 (6.120 sec/step)\n",
      "Step 90: Loss/localization_loss=0.3515, Loss/classification_loss=0.2419 Loss/regularization_loss=0.0855, Loss/total_loss=0.6790, learning_rate=0.0053 (5.963 sec/step)\n",
      "Step 91: Loss/localization_loss=0.5365, Loss/classification_loss=0.2338 Loss/regularization_loss=0.0855, Loss/total_loss=0.8558, learning_rate=0.0053 (5.849 sec/step)\n",
      "Step 92: Loss/localization_loss=0.2962, Loss/classification_loss=0.1908 Loss/regularization_loss=0.0855, Loss/total_loss=0.5725, learning_rate=0.0053 (6.033 sec/step)\n",
      "Step 93: Loss/localization_loss=0.5099, Loss/classification_loss=0.2627 Loss/regularization_loss=0.0855, Loss/total_loss=0.8581, learning_rate=0.0053 (5.955 sec/step)\n",
      "Step 94: Loss/localization_loss=0.5109, Loss/classification_loss=0.1700 Loss/regularization_loss=0.0855, Loss/total_loss=0.7664, learning_rate=0.0053 (5.975 sec/step)\n",
      "Step 95: Loss/localization_loss=0.3925, Loss/classification_loss=0.1586 Loss/regularization_loss=0.0855, Loss/total_loss=0.6367, learning_rate=0.0053 (5.946 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 96: Loss/localization_loss=0.5197, Loss/classification_loss=0.2068 Loss/regularization_loss=0.0855, Loss/total_loss=0.8121, learning_rate=0.0053 (5.957 sec/step)\n",
      "Step 97: Loss/localization_loss=0.5583, Loss/classification_loss=0.2499 Loss/regularization_loss=0.0855, Loss/total_loss=0.8937, learning_rate=0.0054 (5.868 sec/step)\n",
      "Step 98: Loss/localization_loss=0.2556, Loss/classification_loss=0.1468 Loss/regularization_loss=0.0855, Loss/total_loss=0.4880, learning_rate=0.0054 (5.863 sec/step)\n",
      "Step 99: Loss/localization_loss=0.3808, Loss/classification_loss=0.1753 Loss/regularization_loss=0.0855, Loss/total_loss=0.6416, learning_rate=0.0054 (5.906 sec/step)\n",
      "Step 100: Loss/localization_loss=0.2578, Loss/classification_loss=0.1506 Loss/regularization_loss=0.0855, Loss/total_loss=0.4939, learning_rate=0.0054 (5.904 sec/step)\n",
      "Step 101: Loss/localization_loss=0.3684, Loss/classification_loss=0.1521 Loss/regularization_loss=0.0855, Loss/total_loss=0.6060, learning_rate=0.0054 (5.969 sec/step)\n",
      "Step 102: Loss/localization_loss=0.3445, Loss/classification_loss=0.2087 Loss/regularization_loss=0.0855, Loss/total_loss=0.6387, learning_rate=0.0054 (6.004 sec/step)\n",
      "Step 103: Loss/localization_loss=0.2481, Loss/classification_loss=0.1215 Loss/regularization_loss=0.0855, Loss/total_loss=0.4552, learning_rate=0.0054 (6.031 sec/step)\n",
      "Step 104: Loss/localization_loss=0.2534, Loss/classification_loss=0.1042 Loss/regularization_loss=0.0855, Loss/total_loss=0.4431, learning_rate=0.0055 (5.930 sec/step)\n",
      "Step 105: Loss/localization_loss=0.3104, Loss/classification_loss=0.1652 Loss/regularization_loss=0.0855, Loss/total_loss=0.5611, learning_rate=0.0055 (6.034 sec/step)\n",
      "Step 106: Loss/localization_loss=0.3184, Loss/classification_loss=0.1463 Loss/regularization_loss=0.0855, Loss/total_loss=0.5502, learning_rate=0.0055 (5.991 sec/step)\n",
      "Step 107: Loss/localization_loss=0.3287, Loss/classification_loss=0.1972 Loss/regularization_loss=0.0855, Loss/total_loss=0.6114, learning_rate=0.0055 (7.557 sec/step)\n",
      "Step 108: Loss/localization_loss=0.3737, Loss/classification_loss=0.1802 Loss/regularization_loss=0.0855, Loss/total_loss=0.6394, learning_rate=0.0055 (6.816 sec/step)\n",
      "Step 109: Loss/localization_loss=0.5423, Loss/classification_loss=0.2441 Loss/regularization_loss=0.0855, Loss/total_loss=0.8720, learning_rate=0.0055 (6.597 sec/step)\n",
      "Step 110: Loss/localization_loss=0.5881, Loss/classification_loss=0.2692 Loss/regularization_loss=0.0855, Loss/total_loss=0.9429, learning_rate=0.0055 (6.496 sec/step)\n",
      "Step 111: Loss/localization_loss=0.5454, Loss/classification_loss=0.2763 Loss/regularization_loss=0.0855, Loss/total_loss=0.9072, learning_rate=0.0056 (6.223 sec/step)\n",
      "Step 112: Loss/localization_loss=0.3407, Loss/classification_loss=0.1275 Loss/regularization_loss=0.0855, Loss/total_loss=0.5537, learning_rate=0.0056 (6.248 sec/step)\n",
      "Step 113: Loss/localization_loss=0.3678, Loss/classification_loss=0.1396 Loss/regularization_loss=0.0855, Loss/total_loss=0.5929, learning_rate=0.0056 (6.018 sec/step)\n",
      "Step 114: Loss/localization_loss=0.7277, Loss/classification_loss=0.2791 Loss/regularization_loss=0.0855, Loss/total_loss=1.0923, learning_rate=0.0056 (6.052 sec/step)\n",
      "Step 115: Loss/localization_loss=0.3174, Loss/classification_loss=0.2252 Loss/regularization_loss=0.0855, Loss/total_loss=0.6281, learning_rate=0.0056 (6.205 sec/step)\n",
      "Step 116: Loss/localization_loss=0.2863, Loss/classification_loss=0.1497 Loss/regularization_loss=0.0855, Loss/total_loss=0.5216, learning_rate=0.0056 (6.177 sec/step)\n",
      "Step 117: Loss/localization_loss=0.3299, Loss/classification_loss=0.1805 Loss/regularization_loss=0.0855, Loss/total_loss=0.5960, learning_rate=0.0056 (6.124 sec/step)\n",
      "Step 118: Loss/localization_loss=0.2908, Loss/classification_loss=0.1812 Loss/regularization_loss=0.0855, Loss/total_loss=0.5575, learning_rate=0.0057 (5.962 sec/step)\n",
      "Step 119: Loss/localization_loss=0.2848, Loss/classification_loss=0.1316 Loss/regularization_loss=0.0855, Loss/total_loss=0.5019, learning_rate=0.0057 (5.940 sec/step)\n",
      "Step 120: Loss/localization_loss=0.3035, Loss/classification_loss=0.1080 Loss/regularization_loss=0.0855, Loss/total_loss=0.4971, learning_rate=0.0057 (6.050 sec/step)\n",
      "Step 121: Loss/localization_loss=0.3330, Loss/classification_loss=0.1670 Loss/regularization_loss=0.0855, Loss/total_loss=0.5855, learning_rate=0.0057 (6.421 sec/step)\n",
      "Step 122: Loss/localization_loss=0.2506, Loss/classification_loss=0.1529 Loss/regularization_loss=0.0855, Loss/total_loss=0.4890, learning_rate=0.0057 (6.267 sec/step)\n",
      "Step 123: Loss/localization_loss=0.3277, Loss/classification_loss=0.1492 Loss/regularization_loss=0.0855, Loss/total_loss=0.5624, learning_rate=0.0057 (6.242 sec/step)\n",
      "Step 124: Loss/localization_loss=0.3545, Loss/classification_loss=0.1349 Loss/regularization_loss=0.0855, Loss/total_loss=0.5750, learning_rate=0.0057 (6.132 sec/step)\n",
      "Step 125: Loss/localization_loss=0.3020, Loss/classification_loss=0.1220 Loss/regularization_loss=0.0855, Loss/total_loss=0.5095, learning_rate=0.0058 (6.021 sec/step)\n",
      "Step 126: Loss/localization_loss=0.3329, Loss/classification_loss=0.1772 Loss/regularization_loss=0.0855, Loss/total_loss=0.5957, learning_rate=0.0058 (6.029 sec/step)\n",
      "Step 127: Loss/localization_loss=0.3328, Loss/classification_loss=0.1303 Loss/regularization_loss=0.0855, Loss/total_loss=0.5487, learning_rate=0.0058 (6.175 sec/step)\n",
      "Step 128: Loss/localization_loss=0.3080, Loss/classification_loss=0.1355 Loss/regularization_loss=0.0855, Loss/total_loss=0.5290, learning_rate=0.0058 (5.963 sec/step)\n",
      "Step 129: Loss/localization_loss=0.2909, Loss/classification_loss=0.1780 Loss/regularization_loss=0.0855, Loss/total_loss=0.5544, learning_rate=0.0058 (5.960 sec/step)\n",
      "Step 130: Loss/localization_loss=0.2322, Loss/classification_loss=0.1584 Loss/regularization_loss=0.0855, Loss/total_loss=0.4762, learning_rate=0.0058 (6.049 sec/step)\n",
      "Step 131: Loss/localization_loss=0.2324, Loss/classification_loss=0.1483 Loss/regularization_loss=0.0855, Loss/total_loss=0.4663, learning_rate=0.0058 (6.021 sec/step)\n",
      "Step 132: Loss/localization_loss=0.3055, Loss/classification_loss=0.2087 Loss/regularization_loss=0.0855, Loss/total_loss=0.5998, learning_rate=0.0058 (6.297 sec/step)\n",
      "Step 133: Loss/localization_loss=0.3535, Loss/classification_loss=0.1704 Loss/regularization_loss=0.0855, Loss/total_loss=0.6094, learning_rate=0.0059 (6.250 sec/step)\n",
      "Step 134: Loss/localization_loss=0.2738, Loss/classification_loss=0.1772 Loss/regularization_loss=0.0855, Loss/total_loss=0.5366, learning_rate=0.0059 (6.327 sec/step)\n",
      "Step 135: Loss/localization_loss=0.2628, Loss/classification_loss=0.1403 Loss/regularization_loss=0.0855, Loss/total_loss=0.4886, learning_rate=0.0059 (6.197 sec/step)\n",
      "Step 136: Loss/localization_loss=0.2502, Loss/classification_loss=0.1612 Loss/regularization_loss=0.0855, Loss/total_loss=0.4969, learning_rate=0.0059 (6.181 sec/step)\n",
      "Step 137: Loss/localization_loss=0.3075, Loss/classification_loss=0.1288 Loss/regularization_loss=0.0855, Loss/total_loss=0.5218, learning_rate=0.0059 (6.028 sec/step)\n",
      "Step 138: Loss/localization_loss=0.1920, Loss/classification_loss=0.1315 Loss/regularization_loss=0.0855, Loss/total_loss=0.4090, learning_rate=0.0059 (6.028 sec/step)\n",
      "Step 139: Loss/localization_loss=0.3966, Loss/classification_loss=0.1878 Loss/regularization_loss=0.0855, Loss/total_loss=0.6699, learning_rate=0.0059 (6.212 sec/step)\n",
      "Step 140: Loss/localization_loss=0.4105, Loss/classification_loss=0.2391 Loss/regularization_loss=0.0855, Loss/total_loss=0.7351, learning_rate=0.0060 (6.096 sec/step)\n",
      "Step 141: Loss/localization_loss=0.4063, Loss/classification_loss=0.1763 Loss/regularization_loss=0.0855, Loss/total_loss=0.6681, learning_rate=0.0060 (6.151 sec/step)\n",
      "Step 142: Loss/localization_loss=0.2969, Loss/classification_loss=0.1673 Loss/regularization_loss=0.0855, Loss/total_loss=0.5498, learning_rate=0.0060 (6.051 sec/step)\n",
      "Step 143: Loss/localization_loss=0.2757, Loss/classification_loss=0.1601 Loss/regularization_loss=0.0855, Loss/total_loss=0.5214, learning_rate=0.0060 (6.199 sec/step)\n",
      "Step 144: Loss/localization_loss=0.2913, Loss/classification_loss=0.1541 Loss/regularization_loss=0.0855, Loss/total_loss=0.5309, learning_rate=0.0060 (6.159 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 145: Loss/localization_loss=0.2052, Loss/classification_loss=0.1197 Loss/regularization_loss=0.0855, Loss/total_loss=0.4104, learning_rate=0.0060 (6.166 sec/step)\n",
      "Step 146: Loss/localization_loss=0.3141, Loss/classification_loss=0.1119 Loss/regularization_loss=0.0855, Loss/total_loss=0.5115, learning_rate=0.0060 (5.934 sec/step)\n",
      "Step 147: Loss/localization_loss=0.2395, Loss/classification_loss=0.1775 Loss/regularization_loss=0.0855, Loss/total_loss=0.5025, learning_rate=0.0061 (5.986 sec/step)\n",
      "Step 148: Loss/localization_loss=0.3277, Loss/classification_loss=0.1974 Loss/regularization_loss=0.0855, Loss/total_loss=0.6106, learning_rate=0.0061 (6.075 sec/step)\n",
      "Step 149: Loss/localization_loss=0.2753, Loss/classification_loss=0.1180 Loss/regularization_loss=0.0855, Loss/total_loss=0.4788, learning_rate=0.0061 (6.071 sec/step)\n",
      "Step 150: Loss/localization_loss=0.3570, Loss/classification_loss=0.1518 Loss/regularization_loss=0.0855, Loss/total_loss=0.5944, learning_rate=0.0061 (6.016 sec/step)\n",
      "Step 151: Loss/localization_loss=0.2356, Loss/classification_loss=0.1200 Loss/regularization_loss=0.0855, Loss/total_loss=0.4412, learning_rate=0.0061 (5.953 sec/step)\n",
      "Step 152: Loss/localization_loss=0.2856, Loss/classification_loss=0.1198 Loss/regularization_loss=0.0855, Loss/total_loss=0.4909, learning_rate=0.0061 (5.980 sec/step)\n",
      "Step 153: Loss/localization_loss=0.3036, Loss/classification_loss=0.2098 Loss/regularization_loss=0.0855, Loss/total_loss=0.5989, learning_rate=0.0061 (5.924 sec/step)\n",
      "Step 154: Loss/localization_loss=0.2204, Loss/classification_loss=0.1195 Loss/regularization_loss=0.0855, Loss/total_loss=0.4254, learning_rate=0.0062 (5.951 sec/step)\n",
      "Step 155: Loss/localization_loss=0.2695, Loss/classification_loss=0.1341 Loss/regularization_loss=0.0855, Loss/total_loss=0.4892, learning_rate=0.0062 (6.012 sec/step)\n",
      "Step 156: Loss/localization_loss=0.3107, Loss/classification_loss=0.1540 Loss/regularization_loss=0.0855, Loss/total_loss=0.5502, learning_rate=0.0062 (6.014 sec/step)\n",
      "Step 157: Loss/localization_loss=0.3288, Loss/classification_loss=0.1350 Loss/regularization_loss=0.0855, Loss/total_loss=0.5493, learning_rate=0.0062 (6.088 sec/step)\n",
      "Step 158: Loss/localization_loss=0.2100, Loss/classification_loss=0.1036 Loss/regularization_loss=0.0855, Loss/total_loss=0.3992, learning_rate=0.0062 (6.041 sec/step)\n",
      "Step 159: Loss/localization_loss=0.2335, Loss/classification_loss=0.1292 Loss/regularization_loss=0.0855, Loss/total_loss=0.4482, learning_rate=0.0062 (6.093 sec/step)\n",
      "Step 160: Loss/localization_loss=0.2321, Loss/classification_loss=0.1170 Loss/regularization_loss=0.0855, Loss/total_loss=0.4347, learning_rate=0.0062 (6.200 sec/step)\n",
      "Step 161: Loss/localization_loss=0.4078, Loss/classification_loss=0.2154 Loss/regularization_loss=0.0855, Loss/total_loss=0.7088, learning_rate=0.0063 (6.068 sec/step)\n",
      "Step 162: Loss/localization_loss=0.2329, Loss/classification_loss=0.1453 Loss/regularization_loss=0.0855, Loss/total_loss=0.4638, learning_rate=0.0063 (6.031 sec/step)\n",
      "Step 163: Loss/localization_loss=0.2467, Loss/classification_loss=0.1309 Loss/regularization_loss=0.0855, Loss/total_loss=0.4631, learning_rate=0.0063 (6.155 sec/step)\n",
      "Step 164: Loss/localization_loss=0.2306, Loss/classification_loss=0.1373 Loss/regularization_loss=0.0855, Loss/total_loss=0.4534, learning_rate=0.0063 (6.028 sec/step)\n",
      "Step 165: Loss/localization_loss=0.1933, Loss/classification_loss=0.1058 Loss/regularization_loss=0.0855, Loss/total_loss=0.3847, learning_rate=0.0063 (6.104 sec/step)\n",
      "Step 166: Loss/localization_loss=0.2261, Loss/classification_loss=0.1071 Loss/regularization_loss=0.0855, Loss/total_loss=0.4187, learning_rate=0.0063 (6.143 sec/step)\n",
      "Step 167: Loss/localization_loss=0.3956, Loss/classification_loss=0.1072 Loss/regularization_loss=0.0855, Loss/total_loss=0.5883, learning_rate=0.0063 (6.149 sec/step)\n",
      "Step 168: Loss/localization_loss=0.2870, Loss/classification_loss=0.1449 Loss/regularization_loss=0.0855, Loss/total_loss=0.5175, learning_rate=0.0064 (6.111 sec/step)\n",
      "Step 169: Loss/localization_loss=0.2564, Loss/classification_loss=0.1378 Loss/regularization_loss=0.0855, Loss/total_loss=0.4797, learning_rate=0.0064 (6.130 sec/step)\n",
      "Step 170: Loss/localization_loss=0.3316, Loss/classification_loss=0.1057 Loss/regularization_loss=0.0855, Loss/total_loss=0.5229, learning_rate=0.0064 (6.273 sec/step)\n",
      "Step 171: Loss/localization_loss=0.2153, Loss/classification_loss=0.1328 Loss/regularization_loss=0.0855, Loss/total_loss=0.4336, learning_rate=0.0064 (6.153 sec/step)\n",
      "Step 172: Loss/localization_loss=0.1988, Loss/classification_loss=0.1081 Loss/regularization_loss=0.0855, Loss/total_loss=0.3925, learning_rate=0.0064 (6.124 sec/step)\n",
      "Step 173: Loss/localization_loss=0.1781, Loss/classification_loss=0.1061 Loss/regularization_loss=0.0855, Loss/total_loss=0.3697, learning_rate=0.0064 (6.214 sec/step)\n",
      "Step 174: Loss/localization_loss=0.2238, Loss/classification_loss=0.1350 Loss/regularization_loss=0.0855, Loss/total_loss=0.4444, learning_rate=0.0064 (6.297 sec/step)\n",
      "Step 175: Loss/localization_loss=0.2466, Loss/classification_loss=0.0914 Loss/regularization_loss=0.0855, Loss/total_loss=0.4235, learning_rate=0.0065 (6.248 sec/step)\n",
      "Step 176: Loss/localization_loss=0.2564, Loss/classification_loss=0.1387 Loss/regularization_loss=0.0855, Loss/total_loss=0.4806, learning_rate=0.0065 (6.232 sec/step)\n",
      "Step 177: Loss/localization_loss=0.2837, Loss/classification_loss=0.1570 Loss/regularization_loss=0.0855, Loss/total_loss=0.5262, learning_rate=0.0065 (6.326 sec/step)\n",
      "Step 178: Loss/localization_loss=0.3609, Loss/classification_loss=0.1472 Loss/regularization_loss=0.0855, Loss/total_loss=0.5936, learning_rate=0.0065 (6.798 sec/step)\n",
      "Step 179: Loss/localization_loss=0.2861, Loss/classification_loss=0.0970 Loss/regularization_loss=0.0855, Loss/total_loss=0.4686, learning_rate=0.0065 (6.308 sec/step)\n",
      "Step 180: Loss/localization_loss=0.1904, Loss/classification_loss=0.1373 Loss/regularization_loss=0.0855, Loss/total_loss=0.4132, learning_rate=0.0065 (6.139 sec/step)\n",
      "Step 181: Loss/localization_loss=0.3279, Loss/classification_loss=0.1624 Loss/regularization_loss=0.0855, Loss/total_loss=0.5759, learning_rate=0.0065 (6.294 sec/step)\n",
      "Step 182: Loss/localization_loss=0.4250, Loss/classification_loss=0.1473 Loss/regularization_loss=0.0855, Loss/total_loss=0.6579, learning_rate=0.0065 (6.855 sec/step)\n",
      "Step 183: Loss/localization_loss=0.2777, Loss/classification_loss=0.1460 Loss/regularization_loss=0.0855, Loss/total_loss=0.5093, learning_rate=0.0066 (7.027 sec/step)\n",
      "Step 184: Loss/localization_loss=0.1738, Loss/classification_loss=0.1096 Loss/regularization_loss=0.0855, Loss/total_loss=0.3689, learning_rate=0.0066 (6.167 sec/step)\n",
      "Step 185: Loss/localization_loss=0.2897, Loss/classification_loss=0.1377 Loss/regularization_loss=0.0855, Loss/total_loss=0.5129, learning_rate=0.0066 (6.338 sec/step)\n",
      "Step 186: Loss/localization_loss=0.2340, Loss/classification_loss=0.0922 Loss/regularization_loss=0.0855, Loss/total_loss=0.4117, learning_rate=0.0066 (6.298 sec/step)\n",
      "Step 187: Loss/localization_loss=0.2780, Loss/classification_loss=0.1163 Loss/regularization_loss=0.0855, Loss/total_loss=0.4798, learning_rate=0.0066 (6.421 sec/step)\n",
      "Step 188: Loss/localization_loss=0.2696, Loss/classification_loss=0.0986 Loss/regularization_loss=0.0855, Loss/total_loss=0.4537, learning_rate=0.0066 (6.955 sec/step)\n",
      "Step 189: Loss/localization_loss=0.2719, Loss/classification_loss=0.1351 Loss/regularization_loss=0.0855, Loss/total_loss=0.4926, learning_rate=0.0066 (6.855 sec/step)\n",
      "Step 190: Loss/localization_loss=0.2098, Loss/classification_loss=0.1059 Loss/regularization_loss=0.0855, Loss/total_loss=0.4013, learning_rate=0.0067 (6.899 sec/step)\n",
      "Step 191: Loss/localization_loss=0.2232, Loss/classification_loss=0.0844 Loss/regularization_loss=0.0855, Loss/total_loss=0.3932, learning_rate=0.0067 (6.607 sec/step)\n",
      "Step 192: Loss/localization_loss=0.2347, Loss/classification_loss=0.1513 Loss/regularization_loss=0.0855, Loss/total_loss=0.4715, learning_rate=0.0067 (6.257 sec/step)\n",
      "Step 193: Loss/localization_loss=0.2084, Loss/classification_loss=0.0857 Loss/regularization_loss=0.0855, Loss/total_loss=0.3796, learning_rate=0.0067 (6.292 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 194: Loss/localization_loss=0.3397, Loss/classification_loss=0.1136 Loss/regularization_loss=0.0855, Loss/total_loss=0.5388, learning_rate=0.0067 (8.815 sec/step)\n",
      "Step 195: Loss/localization_loss=0.2855, Loss/classification_loss=0.1025 Loss/regularization_loss=0.0855, Loss/total_loss=0.4735, learning_rate=0.0067 (9.790 sec/step)\n",
      "Step 196: Loss/localization_loss=0.2596, Loss/classification_loss=0.0756 Loss/regularization_loss=0.0855, Loss/total_loss=0.4208, learning_rate=0.0067 (10.232 sec/step)\n",
      "Step 197: Loss/localization_loss=0.3882, Loss/classification_loss=0.1494 Loss/regularization_loss=0.0855, Loss/total_loss=0.6231, learning_rate=0.0068 (10.440 sec/step)\n",
      "Step 198: Loss/localization_loss=0.1597, Loss/classification_loss=0.0792 Loss/regularization_loss=0.0855, Loss/total_loss=0.3245, learning_rate=0.0068 (9.462 sec/step)\n",
      "Step 199: Loss/localization_loss=0.2125, Loss/classification_loss=0.1124 Loss/regularization_loss=0.0855, Loss/total_loss=0.4104, learning_rate=0.0068 (9.437 sec/step)\n",
      "Step 200: Loss/localization_loss=0.2635, Loss/classification_loss=0.1174 Loss/regularization_loss=0.0855, Loss/total_loss=0.4664, learning_rate=0.0068 (9.035 sec/step)\n",
      "학습 완료! 0시간 26분 45초\n",
      "학습완료! 1605.9883816242218 초\n"
     ]
    }
   ],
   "source": [
    "trainer.train(continue_training=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e7f635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = \"training_models2_checkpoint\"\n",
    "export_model_path = \"training_models2\"\n",
    "checkpoint = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792d25a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_models2_checkpoint/model.ckpt-200 training_models2_checkpoint/pipeline.config\n",
      "WARNING:tensorflow:From C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000001FF3364A1D0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, BoxPredictor_layer_call_and_return_conditional_losses while saving (showing 5 of 125). These functions will not be directly callable after loading.\n",
      "C:\\Embedded_System\\06_Raspberry Pi\\05_비전(시각형) AI\\HiBready Editor\\resources\\app\\dist-python\\_internal\\python\\3.6.8\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training_models2\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training_models2\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing pipeline config file to training_models2\\pipeline.config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing pipeline config file to training_models2\\pipeline.config\n"
     ]
    }
   ],
   "source": [
    "trainer.setSaveModelDirectory(save_model_path)\n",
    "trainer.freeze_graph(checkpoint=checkpoint, output_directory=export_model_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e9849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
